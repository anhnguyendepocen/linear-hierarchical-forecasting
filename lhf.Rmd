---
title: "Fast forecast reconciliation using linear models"
author:
- familyname: Ashouri
  othernames: Mahsa
  address: Institute of Service Science, National Tsing Hua University, Taiwan
  email: mahsa.ashouri@iss.nthu.edu.tw
  correspondingauthor: true
- familyname: Hyndman
  othernames: Rob J
  address: Monash University, Clayton VIC 3800, Australia
  email: rob.hyndman@monash.edu
- familyname: Shmueli
  othernames: Galit
  address: Institute of Service Science, National Tsing Hua University, Taiwan
  email: galit.shmueli@iss.nthu.edu.tw
abstract: "Forecasting hierarchical or grouped time series involves two steps: computing base forecasts and reconciling the forecasts. Base forecasts can be computed by popular time series forecasting methods such as Exponential Smoothing (ETS) and Autoregressive Integrated Moving Average (ARIMA) models. The reconciliation step is a linear process that adjusts the base forecasts to ensure they are coherent. However using ETS or ARIMA for base forecasts can be computationally challenging when there are a large number of series to forecast, as each model must be numerically optimized for each series. We propose a linear model that avoids this computational problem. The proposed method is very flexible in incorporating external data, handling missing values and model selection. We illustrate our approach using two datasets: monthly Australian domestic tourism and daily Wikipedia pageviews. We compare our approach to reconciliation using ETS and ARIMA, and show that our approach is much faster while providing similar levels of forecast accuracy."
keywords: "hierarchical forecasting, grouped forecasting, reconciling forecast, linear regression"
wpnumber: no/yr
jelcodes: C10,C14,C22
blind: false
cover: false
toc: false
bibliography: references.bib
biblio-style: authoryear-comp
output:
  MonashEBSTemplates::workingpaper:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(knitr)
library(kableExtra)
library(png)
library(grid)
library(gridExtra)
```

# Introduction

Modern data collection tools have dramatically increased the amount of available time series data. For example, the Internet of Things and point-of-sale scanning produce huge volumes of time series in a short period of time. Naturally, there is an interest in forecasting these time series, yet forecasting large collections of time series is computationally challenging.

## Hierarchical and grouped time series

In many cases, these time series can be structured and disaggregated based on hierarchies or groups such as geographic location, product type, gender, etc. An example of hierarchical time series is sales in restaurant chains, which can be disaggregated into different stores and then different types of food or drinks. Figure \@ref(fig:hierarchicalexample) shows a schematic of such a hierarchical time series structure with three levels. The top level (level 0) is the total series, formed by aggregating all the bottom level series. In the middle level (level 1), series are aggregations of their own child series; for instance, series A is the aggregation of AW and AX. Finally, the bottom level series (level 2), includes the most disaggregated series.

```{r hierarchicalexample, out.width = "280px", out.height= "170px", fig.align="center", fig.cap="An example of a two level hierarchical structure."}
knitr::include_graphics("Paper-Figures/hierarchical_example.jpg")
```

Grouped time series involve more complicated aggregation structures compared to strictly hierarchical time series. To take the simplest example, suppose we have two grouping factors which are not nested: sex (Male/Female) and city (New York/San Francisco). The disaggregated series for each combination of sex and city can be combined to form city sub-totals, or sex sub-totals. These sub-totals can be combined to give the overall total. Both sub-totals are of interest.

We can think of such structures as hierarchical time series without a unique hierarchy. A schematic of this grouped time series structure is shown in Figure \@ref(fig:groupexample) with two grouping factors, each of two levels (A/B and C/D). The series in this structure can be split first into groups A and B and then subdivided further into C and D (left side), or split first into C and D and then subdivided into A and B (right side). The final disaggregation is identical in both cases, but the middle level aggregates are different.

```{r groupexample, out.width = "330px", out.height= "180px", fig.align="center", fig.cap="An example of a two level grouped structure."}
G1 <- rasterGrob(as.raster(readPNG("Paper-Figures/Group_1.png")), interpolate = FALSE)
G2 <- rasterGrob(as.raster(readPNG("Paper-Figures/Group_2.png")), interpolate = FALSE)
grid.arrange(G1, G2, ncol = 2)
```

We use the same notation [following @fpp2] for both hierarchical and grouped time series. We denote the total series at time $t$ by $y_t$, and the series at node $Z$ (subaggregation level $Z$) and time $t$ by $y_{Z,t}$. For describing the relationships between series, we use an $n\times m$ matrix, called the 'summing matrix', denoted by $\bm{S}$, in which $n$ is the overall number of nodes and $m$ is the number of bottom level nodes. For example in Figure \@ref(fig:hierarchicalexample), $n = 7$ and $m = 4$, while in Figure \@ref(fig:groupexample), $n=9$ and $m=4$. Then we can write $\bm{y}_t=\bm{S}\bm{b}_t$, where $\bm{y}_t$ is a vector of all the level nodes at time $t$ and $\bm{b}_t$ is the vector of all the bottom level nodes at time $t$. For the example shown in Figure \@ref(fig:groupexample), the equation can be written as follows:
\begin{equation}\label{eq:Smatrixexample}
\begin{pmatrix}
  y_{t}\\y_{A,t}\\y_{B,t}\\y_{C,t}\\y_{D,t}\\y_{AC,t}\\y_{AD,t}\\y_{BC,t}\\y_{BD,t}
\end{pmatrix} =
\begin{pmatrix}
  1&1&1&1\\1&1&0&0\\0&0&1&1\\1&0&1&0\\0&1&0&1\\1&0&0&0\\0&1&0&0\\0&0&1&0\\0&0&0&1\\
\end{pmatrix}
\begin{pmatrix}
  y_{AC,t}\\y_{AD,t}\\y_{BC,t}\\y_{BD,t}\\
\end{pmatrix}.
\end{equation}

## Forecasting hierarchical time series

If we just forecast each series individually, we are ignoring the hierarchical or grouping structure, and the forecasts will not be "coherent" (they will not add up appropriately).

There are several available methods that consider the hierarchical structure information when forecasting time series. These include the top-down [@gross1990disaggregation;@fliedner2001hierarchical], bottom-up [@kahn1998revisiting], middle-out and optimal combination [@hyndman2011optimal] approaches. In the top-down approach, we first forecast the total series and then disaggregate the forecast to form lower level series forecasts based on a set of historical and forecasted proportions [for details see @athanasopoulos2009hierarchical]. In the bottom-up approach, the forecasts in each level of the hierarchy can be computed by aggregating the bottom level series forecasts.  However, we may not get good upper-level forecasts because the most disaggregated series can be noisy and so their forecasts are often inaccurate. In the middle-out approach, the process can be started from one of the middle levels and other forecasts can be computed using aggregation for upper levels and disaggregation for lower levels. Finally, optimal combination uses all the $n$ forecasts for all of the series in the entire structure, and then uses an optimization process to reconcile the resulting forecasts. The advantage of the optimal combination method, compared with the other methods, is that it considers all information in the hierarchy, including any  correlations among the series.

In the optimal combination method, reconciled forecasts can be computed using the following equeation known as weighted least squares (WLS) [@mint2018]
\begin{equation}\label{eq:mint}
  \tilde{\bm{y}}_{h}=\bm{S}(\bm{S}'\bm{W}_h^{-1}\bm{S})^{-1}\bm{S}'\bm{W}_h^{-1}\hat{\bm{y}}_h,
\end{equation}
where $\hat{\bm{y}}_h$ represents a vector of $h$-step-ahead base forecasts for all levels of the hierarchy, and $\bm{W}_h$ is the variance matrix of forecast errors for the $h$-step-ahead base forecasts.

Several possible simpler methods for estimating $\bm{W}_h$ are available. @mint2018 discuss a simple approximation whereby $\bm{W}_h = k_h \bm{\Lambda}$ with $k_h$ being a positive constant, $\bm{\Lambda} = \text{diag}(\bm{S}\bm{1})$, and $\bm{1}$ being a column of 1s. Note that $\bm{\Lambda}$ simply contains the row sums of the summing matrix $\bm{S}$, and that $k_h$ will cancel out in \@ref(eq:mint). Thus
\begin{equation}\label{eq:mint2}
  \tilde{\bm{y}}_{h}=\bm{S}(\bm{S}'\bm{\Lambda}^{-1}\bm{S})^{-1}\bm{S}'\bm{\Lambda}^{-1}\hat{\bm{y}}_h.
\end{equation}

The most computationally challenging part of the optimal combination method is to produce all the base forecasts that make up $\hat{\bm{y}}_h$. In many applications, there may be thousands or even millions of individual series, and each of them must be forecast independently. The most popular time series forecasting methods such as ETS and ARIMA models [@fpp2] involve non-linear optimization routines to estimate the parameters via maximum likelihood estimation. Usually, multiple models are fitted for each series, and the best is select by minimizing Akaike's Information Citerion [@akaike1998information]. This computational challenges increases with the number of lower level series as well as in the number of aggregations of interest.

We therefore propose a new approach to compute the base forecasts that is both computationally fast while maintaining an acceptable forecasting accuracy level.

# Proposed approach: Linear model \label{sec:proposedapproach1}

<!-- Our proposed approach is based on using OLS-LR models for computing base forecasts. We use $\bm{X}_{Z}$ to denote the matrix of $k$ predictors corresponding to the series at node $Z$. Then we can write
\begin{equation}\label{eq:linearmodel}
  \bm{y}_Z = \bm{X}_Z \bm{\beta}_Z+\bm{\varepsilon}_Z
\end{equation}
where $\bm{y}_Z = \{y_{Z,1},\dots,y_{Z,T}\}, \bm{\beta}_Z$ is a vector of coefficients and $\bm{\varepsilon}_Z$ is an error term with mean zero and variance matrix $\sigma^2_Z\bm{I}$. Then using standard regression results \citep{SeberLee}, the OLS estimate of $\bm{\beta}_Z$ is given by
\begin{equation}\label{eq:linearcoefficientstwosteps}
  \hat{\bm{\beta}}_Z = (\bm{X}_{Z}'\bm{X}_Z)^{-1}\bm{X}_Z'\bm{y}_Z,
\end{equation}
and the base forecasts at horizon $h$ can be written as
\begin{equation}
  \hat{y}_{Z,T+h} = \bm{x}_{Z,T+h}'(\bm{X}_{Z}'\bm{X}_Z)^{-1}\bm{X}_Z'\bm{y}_Z,
\end{equation}
with corresponding variance
$$
\hat\sigma^2\left[1 + \bm{x}_{Z,T+h}'(\bm{X}_{Z}'\bm{X}_Z)^{-1}\bm{x}_{Z,T+h}\right],
$$
where $\bm{x}_{Z,T+h}$ denotes the $k$-vector of predictors for time period $T+h$ and
$$
\hat\sigma^2 = \frac{1}{T-k-1}(\bm{y}_Z - \bm{X}_Z\hat{\bm{\beta}}_Z)'(\bm{y}_Z - \bm{X}_Z\hat{\bm{\beta}}_Z).
$$

\todo[inline]{Not complete - Matrix notation: we need to write this for all $\hat{y}_Z$.} -->

Our proposed approach is based on using linear regression models for computing base forecasts. Suppose we have a linear model that we use for forecasting, and we wish to apply it to $N$ different series which have some aggregation constraints. We have observations $y_{t,i}$  from times $t=1,\dots,T$ and series $i=1,\dots,N$. Then
\begin{equation}\label{eq:basicequation}
y_{t,i} = \bm{\beta}_{i}' \bm{x}_{t,i} + \varepsilon_{t,i}
\end{equation}
where $\bm{x}_{t,i}=\{1, x_{t,i,1},\dots,x_{t,i,p}\}$ is a $(p+1)$-vector of regression variables. This equation for all the observations in matrix form can be written as follows:
\begin{equation}\label{eq:linearmodel}
\begin{pmatrix}
\bm{y}_1\\
\bm{y}_2\\
\bm{y}_3 \\
\vdots\\
\bm{y}_N
\end{pmatrix}=
\begin{pmatrix}
\bm{X}_1 & 0        & 0       & \dots  & 0\\
0        & \bm{X}_2 & 0        & \dots  & 0\\
0        & 0        & \bm{X}_3 & \ddots & \vdots \\
\vdots   & \vdots   & \ddots   & \ddots & 0\\
0        & 0    & \dots    & 0      & \bm{X}_N
\end{pmatrix}
\begin{pmatrix}
\bm{\beta}_1\\
\bm{\beta}_2\\
\bm{\beta}_3\\
\vdots\\
\bm{\beta}_N
\end{pmatrix}+
\begin{pmatrix}
\bm{\varepsilon}_1\\
\bm{\varepsilon}_2\\
\bm{\varepsilon}_3\\
\vdots \\
\bm{\varepsilon}_N
\end{pmatrix},
\end{equation}
where $\bm{y}_i = \{y_{1,i}, y_{2,i}, \dots, y_{T,i}\}$ is a $T$-vector, ${\bm{\beta}}_i = \{\beta_{0,i}, \beta_{1,i}, \beta_{2,i}, \dots, \beta_{p,i}\}$ is a $(p+1)$-vector, ${\bm{\varepsilon}}_i = \{\varepsilon_{1,i}, \varepsilon_{2,i}, \dots, \varepsilon_{T,i}\}$ is a $T$-vector and $\bm{X}_i$ is the $T\times (p+1)$-matrix
\begin{equation}\label{eq:Xmatrixdefinition}
\bm{X}_i = \begin{pmatrix}
1 & x_{1,i,1} & x_{1,i,2} & \dots & x_{1,i,p}\\
1 & x_{2,i,1} & x_{2,i,2} & \dots & x_{2,i,p}\\
\vdots & \vdots & \vdots & & \vdots \\
1 & x_{T,i,1} & x_{T,i,2} & \dots & x_{T,i,p}\\
\end{pmatrix}.
\end{equation}

Equation \@ref(eq:linearmodel) can be written as $\bm{Y} = \bm{X} \bm{B} + \bm{E}$, with parameter estimates given by $\hat{\bm{B}} = (\bm{X}'\bm{X})^{-1} \bm{X}'\bm{Y}$. Then the base forecasts are obtained using
\begin{equation}\label{eq:baseforecats}
\hat{\bm{y}}_{t+h} = \bm{X}_{t+h}^* \hat{\bm{B}},
\end{equation}
where $\hat{\bm{y}}_{t+h}$ is an $N$-vector of forecasts, $\hat{\bm{B}}$ comprises $N$ stacked $(p+1)$-vectors of estimated coefficients, and $\bm{X}_{t+h}^*$ is the $N\times N(p+1)$ matrix
\pagebreak[3]
\begin{equation}
\bm{X}_{t+h}^* =
\begin{pmatrix}
\bm{x}_{t+h,1}' & 0                & 0                & \dots  & 0\\
0               & \bm{x}_{t+h,2}' & 0                & \dots  & 0\\
0               & 0                & \bm{x}_{t+h,3}' & \ddots & \vdots \\
\vdots          & \vdots           & \ddots           & \ddots & 0\\
0               & 0                & \dots            & 0      & \bm{x}_{t+h,N}'
\end{pmatrix}.
\end{equation}
Note that we use $\bm{X}^*_{t}$ to distinguish this matrix, which combines $\bm{x}_{t,i}$ across all series for one time from $\bm{X}_i$ which combines $\bm{x}_{t,i}$ across all time for one series.

Finally, we can combine the two linear equations for computing base forecasts and reconciled forecasts (Equations \@ref(eq:mint2) and \@ref(eq:baseforecats)) to obtain the reconciled forecasts with a single equation:
\begin{equation}\label{eq:singlestep}
\tilde{\bm{y}}_{t+h} = \bm{S}(\bm{S}'\bm{\Lambda}\bm{S})^{-1}\bm{S}'\bm{\Lambda}
                        (\bm{X}_{t+h}^* \hat{\bm{B}})
                        = (\bm{S}'\bm{\Lambda}\bm{S})^{-1}\bm{S}'\bm{\Lambda}
                        \bm{X}_{t+h}^* (\bm{X}'\bm{X})^{-1} \bm{X}'\bm{Y}.
\end{equation}

## Simplified formulation for a fixed set of predictors ($\bf {X}$) \label{sec:proposedapproach2}

If we have the same set of predictor variables, $\bm{X}$, for all the series, we can write Equations \@ref(eq:linearmodel) to \@ref(eq:singlestep) more easily using multivariate regression equations, and we can obtain all the reconciled forecasts for all the series in one equation.  In that case, Equation \@ref(eq:linearmodel) can be rearranged as follows:
\begin{equation}\label{eq:linearmodelsameX}
  \begin{pmatrix}
  y_{11} & \dots & y_{1N}\\
  y_{21} & \dots & y_{2N}\\
  \vdots &       & \vdots\\
  y_{T1} & \dots & y_{TN}
  \end{pmatrix} =
  \begin{pmatrix}
  1      & X_{11} & \dots & X_{1p}\\
  1      & X_{21} & \dots & X_{2p}\\
  \vdots & \vdots &       & \vdots\\
  1      & X_{T1} & \dots & X_{Tp}
  \end{pmatrix}
  \begin{pmatrix}
  \beta_{01} & \dots & \beta_{0N}\\
  \beta_{11} & \dots & \beta_{1N}\\
  \vdots     &       & \vdots\\
  \beta_{p1} & \dots & \beta_{pN}
  \end{pmatrix} \\
  +
  \begin{pmatrix}
  \varepsilon_{11} & \dots & \varepsilon_{1N}\\
  \varepsilon_{21} & \dots & \varepsilon_{2N}\\
  \vdots           &       & \vdots\\
  \varepsilon_{T1} & \dots & \varepsilon_{TN}
  \end{pmatrix}
\end{equation}

where $\bm{Y}$, $\bm{X}$, $\bm{B}$ and $\bm{E}$ are now matrices of size $T\times N$, $T\times (p+1)$, $(p+1)\times N$ and $T \times N$, respectively. Equations \@ref(eq:baseforecats) to \@ref(eq:singlestep) can be written accordingly using Equation \@ref(eq:linearmodelsameX) and here $\bm{X}^*_{t+h,i} = \bm{X}^*_{t+h}$, where $\bm{X}^*_{t+h}$ is an $h\times (p+1)$ matrix.

<!--We can represent Equation \@ref(eq:linearmodelsameX) as follows
\begin{equation}\label{eq:linearmodelmatrixsameX}
\bm{Y}= \bm{X} \bm{B} + \bm{E},
\end{equation}
where $\bm{Y}$, $\bm{X}$, $\bm{B}$ and $\bm{E}$ are now matrices of size $T\times N$, $T\times (p+1)$, $(p+1)\times N$ and $T \times N$, respectively. Using Equation \@ref(eq:linearmodelmatrixsameX), parameter estimates are given by
\begin{equation}
\hat{\bm{B}} = (\bm{X}'\bm{X})^{-1} \bm{X}'\bm{Y}.
\end{equation}
Then the base forecasts can be written as
\begin{equation}
\begin{pmatrix}
 \hat{y}_{t+1,1} & \hat{y}_{t+1,2} & \dots & \hat{y}_{t+1,N}\\
 \hat{y}_{t+2,1} & \hat{y}_{t+2,2} & \dots & \hat{y}_{t+2,N}\\
 \vdots & \vdots & & \vdots\\
 \hat{y}_{t+h,1} & \hat{y}_{t+h,2} & \dots & \hat{y}_{t+h,N}\\
 \end{pmatrix} =
 \begin{pmatrix}
 1 & X_{t+1,1} & X_{t+1,2} & \dots & X_{t+1,p}\\
 1 & X_{t+2,1} & X_{t+2,2} & \dots & X_{t+2,p}\\
 \vdots & \vdots & & \vdots\\
 1 & X_{t+h,1} & X_{t+h,2} & \dots & X_{t+h,p}
 \end{pmatrix}
 \begin{pmatrix}
 \hat\beta_{01} & \hat\beta_{02} & \dots & \hat\beta_{0N}\\
 \hat\beta_{11} & \hat\beta_{12} & \dots & \hat\beta_{1N}\\
 \vdots & \vdots & & \vdots\\
 \hat\beta_{p1} & \hat\beta_{p2} & \dots & \hat\beta_{pN}
 \end{pmatrix},
\end{equation}
or in shorter form,
\begin{equation}\label{eq:baseforecatssameX}
\hat{\bm{Y}} = \bm{X}^* \hat{\bm{B}}.
\end{equation}
Then the reconciliationfor all the forecasted points, $h$, and all the series, $N$,  can be written as
\begin{equation}\label{eq:recforecastssameX}
\tilde{\bm{Y}} = (\bm{S}'\bm{W}\bm{S})^{-1}\bm{S}'\bm{W} \hat{\bm{Y}},
\end{equation}
where again $\bm{W}$ is an $N\times N$ diagonal matrix with $(i,i)$th element $\sigma_i^2$, and $\bm{S}$ is the summation matrix containing the aggregation constraints. Also in the above equation, $\tilde{\bm{Y}}$ includes all the reconciled forecasts for all the bottom level series.

At the end, we can combine the two linear equations for computing base forecasts and reconciliation (Equations \@ref(eq:baseforecatssameX) and \@ref(eq:recforecastssameX)) to obtain the reconciled forecasts  with a single equation
\begin{equation}\label{eq:singlestepsameX}
\tilde{\bm{Y}} = (\bm{S}'\bm{W}\bm{S})^{-1}\bm{S}'\bm{W}
                        (\bm{X}^* \hat{\bm{B}})
                        = (\bm{S}'\bm{W}\bm{S})^{-1}\bm{S}'\bm{W}
                        (\bm{X}^* (\bm{X}'\bm{X})^{-1} \bm{X}'\bm{Y})
\end{equation}
!-->

## OLS predictors

As an example of the $\bm{X}_t$ matrix in Equation \@ref(eq:linearmodel), we can refer to the set of predictors proposed in @ashouri2018 for modeling trend, seasonality and autocorrelation by using lagged values ($y_{t-1}$, $y_{t-2}$, \dots), trend variables and seasonal dummy variables:
\begin{equation}\label{eq:linearmodelexample}
    y_t = \alpha_0 + \alpha_1 t + \beta_1 s_{1,t} + \cdots + \beta_{m-1} s_{m-1,t} + \gamma_1 y_{t-1} + \cdots + \gamma_p y_{t-p} + \delta z_t + \varepsilon_t.
\end{equation}
Here, $s_{j,t}$ is a dummy variable taking value 1 if time $t$ is in season $j$ ($j=1, 2, \dots, m$), $y_{t-k}$ is the $k$th lagged value for $y_t$ and $z_t$ is some external information at time $t$. The seasonal period $m$ depends on the problem; for instance, if we have daily data with day-of-week seasonality, then $m=7$.

In Equation \@ref(eq:linearmodelexample) because of using lags and external series as predictors we do not have same set of predictors for all the series , $y_t$. However, if we just use trend and seasonality dummies as the predictors then the simpler equations explained in Section \@ref(sec:proposedapproach1), can be written using multivariate regression models.

While OLS is popular in practice for forecasting time series, it is often frowned upon due to its independence assumption. This can cause issue for parametric inference but is less of a problem for forecasting. In fact it often performs sufficiently well for forecasting as can be seen by its popular use in practice. Further, the use of autoregressive terms in the above model should model most of the autocorrelation in the data.

## Computational considerations

There are two ways for computing above forecasts. In the first way we can create matrices, $Y$, $X$ and $E$. Also we need to compute the inverse matrix to compute the coefficients. To avoid numerical issues due to matrix inversion, one can use `separate regression models' to compute the coefficients for each linear model individually.

Although the matrix, $\bf X'X$, for  which we want to compute the inverse is sparse and block diagonal, it is still faster and more accurate to use the `separate regression models' approach. In [Appendix B](#appendixB) we give the forecast results comparisons for Australian domestic tourism example using these two computation approaches.

# Applications

In this section we illustrate our approach using two examples: forecasting monthly Australian domestic tourism and forecasting daily Wikipedia pageviews. We compare the forecasting accuracy of ETS, ARIMA and the proposed linear OLS forecasting model, with and without the reconciliation step. For comparing these methods, we use the average of Root Mean Square Errors (RMSEs) across all series and also display box plots for forecast errors along with the raw forecast errors.

The two datasets differ in terms of structure, size and behavior. The tourism data contains 304 series with both hierarchical and grouped structure, while the Wikipedia pageviews dataset contains 913 series with grouped structure. The tourism dataset has strong seasonality while the Wikipedia data are noiser.

We apply two methods for generating $h$-step-ahead forecasts, which differ in how they handle unobserved lagged values as inputs. The first approach is *rolling origin*, in that it uses actual values, even when they are future to the forecast origin. This value is known to us because it is in the test set. We call these "rolling origin" forecasts. In the second method, we follow an *fixed origin* approach, and we replace lagged values of $y$ by their forecasts if they occur at periods after the forecast origin. We call these "fixed origin" forecasts.

In the following two applications, we used the unweighted reconciliation approach from Equation \@ref(eq:initialW) ($W=I$). In [Appendix C](#appendixC), we repeat some of the results for the Australian domestic tourism dataset using WLS reconciliation approach in Equation \@ref(eq:mint).

## Australian domestic tourism

```{r Readtourism, results='hide'}
error.tourism <- readr::read_csv("Paper-Figures/results_Tourism/error.tourism.csv")
# Read csv files for tourism results
rmse <- error.tourism %>%
  group_by(Rec, Method, Level, ForecastInterval) %>%
  summarise(
    rmse = sqrt(mean(Value^2))
  ) %>%
  spread(value = rmse, key = Method) %>%
  ungroup() %>%
  select(Rec, ForecastInterval, Level, ETS, ARIMA, OLS) %>%
  mutate(
    Level = str_replace(Level, "level([0-9])", "Level \\1")
  )
easter.error.tourism <- readr::read_csv("Paper-Figures/results_Tourism/error.tourism.easter.csv")
easter.rmse <- easter.error.tourism %>%
  group_by(Rec, Method, Level, ForecastInterval) %>%
  summarise(
    rmse = sqrt(mean(Value^2))
  ) %>%
  spread(value = rmse, key = Method) %>%
  ungroup() %>%
  select(Rec, ForecastInterval, Level, ARIMAX, OLSX) %>%
  mutate(
    Level = str_replace(Level, "level([0-9])", "Level \\1")
  ) %>%
  left_join(rmse) %>%
  select(-ETS)
forecast.tourism <- readr::read_csv("Paper-Figures/results_Tourism/forecast.tourism.csv") %>%
  select(-X1) %>%
  gather(-Series, -ForecastInterval, -date, key = "Method", value = "Count") %>%
  mutate(
    Rec = str_extract(Method, "[a-z]*$"),
    Rec = if_else(Rec == "ctual", "Actual", Rec),
    Model = str_extract(Method, "^[A-Z]*"),
    Model = if_else(Model == "A", "Actual", Model)
  )
```

This dataset has 19 years of monthly visitor nights in Australia by Australian tourists, a measure used as an indicator of tourism activity [@mint2018]. The data were collected by computer-assisted telephone interviews with 120,000 Australians aged 15 and over [@researchAustralia2005]. The dataset includes 304 time series each of length 228 observations. The hierarchy and grouping structure for this dataset is made using geographic and purpose of travel information.

```{r Australiageographicaldivision, results='asis'}
table1 <- matrix(NA, nrow = 58, ncol = 6)
colnames(table1) <- c("Series", "Name", "Label", "Series", "Name", "Label")
table1[, 1] <- c("Total", "1", "State", "2", "3", "4", "5", "6", "7", "8", "Zone", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "Region", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54")
table1[, 2] <- c("", "Australia", "", "NSW", "VIC", "QLD", "SA", "WA", "TAS", "NT", "", "Metro NSW", "Nth Coast NSW", "Sth Coast NSW", "Sth NSW", "Nth NSW", "ACT", "Metro VIC", "West Coast VIC", "East Coast VIC", "Nth East VIC", "Nth West VIC", "Metro QLD", "Central Coast QLD", "Nth Coast QLD", "Inland QLD", "Metro SA", "Sth Coast SA", "Inland SA", "West Coast SA", "West Coast WA", "Nth WA", "Sth WA", "Sth TAS", "Nth East TAS", "Nth West TAS", "Nth Coast NT", "Central NT", "", "Sydney", "Central Coast", "Hunter", "North Coast NSW", "Northern Rivers Tropical NSW", "South Coast", "Snowy Mountains", "Capital Country", "The Murray", "Riverina", "Central NSW", "New England North West", "Outback NSW", "Blue Mountains", "Canberra", "Melbourne", "Peninsula", "Geelong", "Western")
table1[, 3] <- c("", "Total", "", "A", "B", "C", "D", "E", "F", "G", "", "AA", "AB", "AC", "AD", "AE", "AF", "BA", "BB", "BC", "BD", "BE", "CA", "CB", "CC", "CD", "DA", "DB", "DC", "DD", "EA", "EB", "EC", "FA", "FB", "FC", "GA", "GB", "", "AAA", "AAB", "ABA", "ABB", "ABC", "ACA", "ADA", "ADB", "ADC", "ADD", "AEA", "AEB", "AEC", "AED", "AFA", "BAA", "BAB", "BAC", "BBA")
table1[, 4] <- c("Region", "55", "56", "57", "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96", "97", "98", "99", "100", "101", "102", "103", "104", "105", "106", "107", "108", "109", "110", "111")
table1[, 5] <- c("", "Lakes", "Gippsland", "Phillip Island", "General Murray", "Goulburn", "High Country", "Melbourne East", "Upper Yarra", "Murray East", "Wimmera+Mallee", "Western Grampians", "Bendigo Loddon", "Macedon", "Spa Country", "Ballarat", "Central Highlands", "Gold Coast", "Brisbane", "Sunshine Coast", "Central Queensland", "Bundaberg", "Fraser Coast", "Mackay", "Whitsundays", "Northern", "Tropical North Queensland", "Darling Downs", "Outback", "Adelaide", "Barossa", "Adelaide Hills", "Limestone Coast", "Fleurieu Peninsula", "Kangaroo Island", "Murraylands", "Riverland", "Clare Valley", "Flinders Range and Outback", "Eyre Peninsula", "Yorke Peninsula", "Australia's Coral Coast", "Experience Perth", "Australia's SouthWest", "Australia's North West", "Australia's Golden Outback", "Hobart and the South", "East Coast", "Launceston, Tamar and the North", "North West", "Wilderness West", "Darwin", "Kakadu Arnhem", "Katherine Daly", "Barkly", "Lasseter", "Alice Springs", "MacDonnell")
table1[, 6] <- c("", "BCA", "BCB", "BCC", "BDA", "BDB", "BDC", "BDD", "BDE", "BDF", "BEA", "BEB", "BEC", "BED", "BEE", "BEF", "BEG", "CAA", "CAB", "CAC", "CBA", "CBB", "CBC", "CBD", "CCA", "CCB", "CCC", "CDA", "CDB", "DAA", "DAB", "DAC", "DBA", "DBB", "DBC", "DCA", "DCB", "DCC", "DCD", "DDA", "DDB", "EAA", "EAB", "EAC", "EBA", "ECA", "FAA", "FBA", "FBB", "FCA", "FCB", "GAA", "GAB", "GAC", "GBA", "GBB", "GBC", "GBD")
kable(table1,
  align = c("r", "l", "l", "r", "l", "l"), format = "latex", booktabs = TRUE, linesep = "", longtable = TRUE,
  caption = "Australia geographic hierarchical structure."
) %>%
  kable_styling(position = "center", font_size = 9)
```

```{r Australiahierarchystructure, out.width = "450px", out.height= "150px", fig.align="center", fig.cap="Australian geographic hierarchical structure."}
knitr::include_graphics("Paper-Figures/Australian_hierarchy_structure.jpg")
```

```{r Australiahierarchystructuremap, out.width = "450px", out.height= "360px", fig.align="center", fig.cap="Australia tourism region map - colors represent states."}
knitr::include_graphics("Paper-Figures/ausTurRegions.pdf")
```

\newpage

In this dataset we have three levels of geographic divisions in Australia. In the first level, Australia is divided into seven 'States' including New South Wales (NSW), Victoria (VIC), Queensland (QLD), South Australia (SA), Western Australia (WA), Tasmania (TAS) and Northern Territory (NT). In the second and third levels, it is divided into 27 'Zones' and 76 'Regions' (for details about Australia geographic divisions see Figure \@ref(fig:Australiahierarchystructure) and Table \@ref(tab:Australiageographicaldivision) and also Figure \@ref(fig:Australiahierarchystructuremap) which shows Australia map divided by tourism region and colored by states^[For more information about the map: \url{https://www.tra.gov.au/tra/2016/Tourism_Region_Profiles/Region_profiles/index.html}]).

For 'Purpose' we have four groups: Holiday (Hol), Visiting friends and relatives (Vis), Business (Bus) and Other (Oth). Based on the geographic hierarchy and purpose grouping, we end up with 8 hierarchical levels with 555 series in total:

- Level 0 = Total for Australia
- Level 1 = State totals
- Level 2 = Zone totals
- Level 3 = Region totals
- Level 4 = Purpose totals
- Level 5 = State $\times$ Purpose totals
- Level 6 = Zone $\times$ Purpose totals
- Level 7 = bottom level series

```{r Australiageographicalpurposedivision, results='asis'}
table1 <- matrix(NA, nrow = 5, ncol = 4)
table1[, 1] <- c("Australia", "State", "Zone", "Region", "Total")
table1[, 2] <- c("1", "7", "27", "76", "111")
table1[, 3] <- c("4", "28", "108", "304", "444")
table1[, 4] <- c("5", "35", "135", "380", "555")
kable(table1,
  align = c("l", "r", "r", "r"), format = "latex", booktabs = T, linesep = "", caption = "Number of Australian domestic tourism series in each level of the hierarchy and group structure.",
  col.names = c("Geographic division", "# series (geographic division)", "# series (purpose of travel)", "Total")
) %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

We report the forecast results for all these hierarchical levels, as well as the average RMSE across all the levels of the hierarchy. We used different predictors in the OLS predictor
matrix for the rolling and fixed origin approaches.  For the rolling origin model, we included a linear trend, 11 dummy variables, and 12 lags. For the fixed origin model, we included a quadratic trend, 11 dummy variables, and lags 1 and 12. This is intended to capture the monthly seasonality. In addition, before running the model, we partition the data into training and test sets, with the last 24 months (2 years) as our test set, and the rest as our training set.


```{r Tourismdataresulrolling, results='asis', dependson="Readtourism"}
bind_cols(
  filter(rmse, ForecastInterval == "1Step", Rec == "unrec") %>% select(-Rec, -ForecastInterval),
  filter(rmse, ForecastInterval == "1Step", Rec == "rec") %>% select(-Rec, -ForecastInterval, -Level)
) %>%
  kable(
    booktabs = TRUE, format = "latex", digits = 1, linesep = "",
    caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - Rolling origin 24-step-ahead - Tourism dataset",
    col.names = c("Level", rep(c("ETS", "ARIMA", "OLS"), 2))
  ) %>%
  add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

```{r TourismdataresultRMSE, results='asis', dependson="Readtourism"}
bind_cols(
  filter(rmse, ForecastInterval == "24Step", Rec == "unrec") %>% select(-Rec, -ForecastInterval),
  filter(rmse, ForecastInterval == "24Step", Rec == "rec") %>% select(-Rec, -ForecastInterval, -Level)
) %>%
  kable(
    booktabs = TRUE, format = "latex", digits = 1, linesep = "",
    caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - Fixed origin 24-step-ahead - Tourism dataset",
    col.names = c("Level", rep(c("ETS", "ARIMA", "OLS"), 2))
  ) %>%
  add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
  kable_styling(position = "center")
```

In Tables \@ref(tab:Tourismdataresulrolling) and \@ref(tab:TourismdataresultRMSE), we show the average RMSE for the 1-month and 24-month forecasts. Methods include ETS, ARIMA and our proposed OLS forecasting model. In Table \@ref(tab:Tourismdataresulrolling) we forecast 24 periods ahead by computing rolling origin forecasts, rolling forward month by month. In Table \@ref(tab:TourismdataresultRMSE) we generate fixed origin 24-step-ahead forecasts. In these tables we show forecasts with and without reconciliation.

These results show that our proposed OLS forecasting model produces forecast accuracy similar to ETS and ARIMA, which are computationally heavy for many time series. Also they show the usefulness of the reconciliation in decreasing the average RMSE in all the three methods. Except for the total series, reconciliation can help in forecasting all the hierarchical levels. Also, because the higher level series have higher counts, the errors are larger in magnitude (see Figures \@ref(fig:boxplotrollingtourism) and \@ref(fig:boxplottourism)). To better compare errors across all the hierarchy levels we scaled  the errors (See [Appendix A](#appendixA)).

In Figures \@ref(fig:boxplotrollingtourism) and \@ref(fig:boxplottourism) we display the error box plots for both reconciled and unreconciled forecasts using all three methods, for 1-step ahead and 24-steps ahead. In these figures we can visualize the error distributions across all the models, as well as the usefulness of the reconciliation step in improving the forecasts. In particular, we see that as expected by applying rolling origin 24-step-ahead forecasts, the error densities are closer and more distributed around zero than the fixed origin 24-step-ahead forecasts.

Figures \@ref(fig:forecstrolling24tourismtotal) and \@ref(fig:forecstrolling24tourism) show the rolling and fixed origin 24-step-ahead forecast results for the total series and one of the bottom level series, 'BACBus' (Geelong - Business). In these plots we have both reconciled (solid lines) and unreconciled (dashed lines) forecasts and we see that the reconciliation step improves the forecasts in this series. We also see that the OLS model forecast accuracy is similar to the other two methods.

```{r boxplotrollingtourism, fig.align="center", fig.cap="Box plots of forecast errors from reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for rolling origin 24-step-ahead tourism demand.", out.width="100%"}
## 1-step-ahead
error.tourism %>%
  filter(ForecastInterval == "1Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  )) %>%
  ggplot(aes(x = id, y = Value, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 4, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

```{r boxplottourism, fig.align="center", fig.cap="Box plots of forecast errors for reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for fixed origin 24-step-ahead tourism demand.", out.width="100%"}
## 24-step-ahead
error.tourism %>%
  filter(ForecastInterval == "24Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  )) %>%
  ggplot(aes(x = id, y = Value, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 4, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

```{r forecstrolling24tourismtotal, fig.align="center", fig.cap="The actual test set for the 'Total series' compared to the forecasts from reconciled and unreconciled ETS, ARIMA and OLS methods for rolling and fixed origin 24-step-ahead tourism demand.", out.width="100%"}
### total series
g1 <- forecast.tourism %>%
  filter(Series == "Total", ForecastInterval == "1Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Rolling origin 24-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(linetype = FALSE)
g2 <- forecast.tourism %>%
  filter(Series == "Total", ForecastInterval == "24Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Fixed origin 24-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(color = FALSE)
gridExtra::grid.arrange(g1, g2, nrow = 2)
```

```{r forecstrolling24tourism, fig.align="center", fig.cap="The actual test set for the 'BACBus' bottom level series compared to the forecasts from reconciled and unreconciled ETS, ARIMA and OLS methods for rolling and fixed origin 24-step-ahead tourism demand.", out.width="100%"}
### one of the bottom level series
p1 <- forecast.tourism %>%
  filter(Series == "BACBus", ForecastInterval == "1Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Rolling origin 24-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(linetype = FALSE)
p2 <- forecast.tourism %>%
  filter(Series == "BACBus", ForecastInterval == "24Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Fixed origin 24-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(color = FALSE)
gridExtra::grid.arrange(p1, p2, nrow = 2)
```

\newpage

Table \@ref(tab:Tourismdatacomputationtime) compares the computation time of the three methods for rolling and fixed origin 24-step-ahead forecasting. We see that the OLS forecasting model is much faster compared to the other methods. Also, since reconciliation is a linear process, in all methods it is very fast and does not affect computation time significantly.

```{r Tourismdatacomputationtime, results='asis'}
table2 <- matrix(NA, nrow = 3, ncol = 5)
table2[, 1] <- c("ETS", "ARIMA", "OLS")
table2[, 2] <- c("10924.57", "31146.38", "48.40")
table2[, 3] <- c("10924.60", "31146.52", "48.31")
table2[, 4] <- c("407.10", "1116.15", "17.42")
table2[, 5] <- c("407.15", "1116.19", "17.80")
kable(table2,
  align = c("l", rep("r", 4)), format = "latex", booktabs = TRUE, linesep = "",
  caption = "Computation time (seconds) for ETS, ARIMA and OLS with and without reconciliation - Rolling and fixed origin 24-step-ahead - Tourism dataset",
  col.names = c("", "Unreconciled", "Reconciled", "Unreconciled", "Reconciled")
) %>%
  column_spec(1:3, width = "3cm") %>%
  add_header_above(c("", "Rolling origin" = 2, "Fixed origin" = 2)) %>%
  kable_styling(position = "center", full_width = FALSE)
```

Since we are using a linear model, we can easily include exogenous variables which can often be helpful in improving forecast accuracy. In this application, we tried including an "Easter" dummy variable indicating the timing of Easter, but its affect on forecast accuracy was minimal, so it was omitted in the model reported here.

<!--Now since we are using a linear model for forecasting, we can easily include information about the timing of Easter to check its effect on forecasting results. We also add this information on ARIMA models and compare with the OLS forecasting model. In Tables \@ref(tab:easterroolingRMSE) and \@ref(tab:easterRMSE), we display the average RMSE of ARIMA and OLS including the easter information, ARIMAX and OLSX, across different levels with and without reconciliation. These tables are for 1-step-ahead and 24-step-ahead forecasts. Figure \@ref(fig:forecstrolling24tourism) shows the 1-step-ahead and 24-step-ahead forecast results for one of the bottom level series, BACBus (Geelong/Business). In these plots we have both reconciled (solid lines) and unreconciled (dashed lines) forecasts and we see that the reconciliation step improves the forecasts in this series. We also see that the OLS model forecast accuracy is similar to the other two methods. These results show that adding this external data does not change the forecasting results significantly. However in different cases, trying different external data can be helpful in improving the forecasting results.

```{r easterroolingRMSE, results='asis'}
bind_cols(
  filter(easter.rmse, ForecastInterval == "1Step", Rec == "unrec") %>% select(-Rec, -ForecastInterval),
  filter(easter.rmse, ForecastInterval == "1Step", Rec == "rec") %>% select(-Rec, -ForecastInterval, -Level)
) %>%
  select(Level, ARIMA, OLS, ARIMAX, OLSX, ARIMA1, OLS1, ARIMAX1, OLSX1) %>%
  kable(
    booktabs = TRUE, format = "latex", digits = 1, linesep = "",
    caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - 1-step-ahead - Tourism dataset",
    col.names = c("Level", rep(c("ARIMA", "OLS", "ARIMAX", "OLSX"), 2))
  ) %>%
  add_header_above(c("", "Unreconciled" = 4, "Reconciled" = 4)) %>%
  kable_styling(position = "center")
```

```{r easterRMSE, results='asis'}
bind_cols(
  filter(easter.rmse, ForecastInterval == "24Step", Rec == "unrec") %>% select(-Rec, -ForecastInterval),
  filter(easter.rmse, ForecastInterval == "24Step", Rec == "rec") %>% select(-Rec, -ForecastInterval, -Level)
) %>%
  select(Level, ARIMA, OLS, ARIMAX, OLSX, ARIMA1, OLS1, ARIMAX1, OLSX1) %>%
  kable(
    booktabs = TRUE, format = "latex", digits = 1, linesep = "",
    caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - 24-step-ahead - Tourism dataset",
    col.names = c("Level", rep(c("ARIMA", "OLS", "ARIMAX", "OLSX"), 2))
  ) %>%
  add_header_above(c("", "Unreconciled" = 4, "Reconciled" = 4)) %>%
  kable_styling(position = "center")
```

\todo[inline]{I can't see much point including these Easter results.}
!-->

\FloatBarrier

## Wikipedia pageviews: Grouped structure

The second dataset consists of one year of daily data (2016-06-01 to 2017-06-29) on Wikipedia pageviews for the most popular social networks articles [@ashouri2018]. This dataset is noisier compared with the Australian monthly tourism data and forecasting its series is more challenging. It has a grouped structure, with grouping attributes: 'Agent': Spider, User, 'Access': Desktop, Mobile app, Mobile web, 'Language': en (English), de (German), es (Spanish), zh (Chinese) and 'Purpose': Blogging related, Business, Gaming, General purpose, Life style, Photo sharing, Reunion, Travel, Video (check Table \@ref(tab:wikipediagroupingstructure)). We display the group structure in Table \@ref(tab:wikipediagroupingstructure) and Figure \@ref(fig:wikigroupstructure). In Figure \@ref(fig:wikigroupstructure) we use one possible hierarchy for this dataset, but the order of the hierarchy can be switched.
The final dataset includes 913 time series, each with length 394. The group structure and different levels include:

- Level 0 = Total
- Level 1 = Agent
- Level 2 = Access
- Level 3 = Language
- Level 4 = Purpose
- Level 5 = bottom level series

For this daily dataset, in the OLS forecasting model we include in the predictor matrix a quadratic trend, 6 seasonal dummies and all 7 lags for rolling, and for fixed origin model we use a quadratic trend, 6 seasonal dummies and lags 1 and 7. We partitioned the data into two parts training and test sets. We used the last 28 days for our test set and the rest for the training set.

```{r Readwikipedia, results='hide'}
error.wiki <- readr::read_csv("Paper-Figures/results_Wikipedia/error.wiki.csv")
# Read csv files for tourism results
rmse2 <- error.wiki %>%
  group_by(Rec, Method, Level, ForecastInterval) %>%
  summarise(
    rmse = sqrt(mean(Value^2))
  ) %>%
  spread(value = rmse, key = Method) %>%
  ungroup() %>%
  select(Rec, ForecastInterval, Level, ETS, ARIMA, OLS) %>%
  mutate(
    Level = str_replace(Level, "level([0-9])", "Level \\1")
  )

forecast.wiki <- readr::read_csv("Paper-Figures/results_Wikipedia/forecast.wiki.csv") %>%
  select(-X1) %>%
  gather(-Series, -ForecastInterval, -date, key = "Method", value = "Count") %>%
  mutate(
    Rec = str_extract(Method, "[a-z]*$"),
    Rec = if_else(Rec == "ctual", "Actual", Rec),
    Model = str_extract(Method, "^[A-Z]*"),
    Model = if_else(Model == "A", "Actual", Model)
  )
```

```{r wikipediagroupingstructure, echo=FALSE, message = FALSE, results='asis'}
table1 <- matrix(NA, nrow = 13, ncol = 4)
colnames(table1) <- c("Grouping", "Series", "Grouping", "Series")
table1[, 1] <- c("Total", "", "Agent", "", "", "Access", "", "", "", "Language", "", "", "")
table1[, 2] <- c("", "1. Social Network", "", "2. Spider", "3. User", "", "4. Desktop", "5. Mobile app", "6. Mobile web", "", "7. en (English)", "8. de (German)", "9. es (Spanish)")
table1[, 3] <- c("Language", "", "Purpose", "", "", "", "", "", "", "", "", "", "")
table1[, 4] <- c("", "10. zh (Chinese)", "", "11. Blogging related", "12. Business", "13. Gaming", "14. General purpose", "15. Life style", "16. Photo sharing", "17. Reunion", "18. Travel", "19. Video", "")
kable(table1, format = "latex", booktabs = TRUE, linesep = "", caption = "Social networking Wikipedia article grouping structure") %>%
  kable_styling(position = "center")
```

```{r wikigroupstructure, echo=FALSE, out.width = "500px", out.height= "250px", fig.align="center", fig.cap="One of the possible hierarchical structures for the Wikipedia pageview dataset."}
knitr::include_graphics("Paper-Figures/Wiki_group_structure.jpg")
```

Table \@ref(tab:wikipediadataresulrolling), \@ref(tab:wikipediadataresultRMSE) and \@ref(tab:wikipediadatacomputationtime) represent the RMSE results and computation time. Although these time series are noisier, we still get acceptable results for the OLS forecasting model compared with ETS and ARIMA. In this case, we get similar results with and without the reconciliation step.

Figures \@ref(fig:boxplotrollingwiki) and \@ref(fig:boxplotwiki) display the forecast error box plot. These plots are for rolling and fixed origin 28-step-ahead forecasts in each level of grouping. Further, we can see that the error distribution is almost similar in all levels across the different methods. The only exception is the Total series, where ETS performs significantly better than ARIMA and OLS. We also note that the reconciliation is less effective. As in the tourism example, in higher levels, series have higher counts and therefore their error magnitudes are larger. <!--In  [Appendix B](#appendixB) we display box plots for the errors devided by the error range for easier comparison.-->

```{r wikipediadataresulrolling, results='asis', dependson="Readwikipedia"}
bind_cols(
  filter(rmse2, ForecastInterval == "1Step", Rec == "unrec") %>% select(-Rec, -ForecastInterval),
  filter(rmse2, ForecastInterval == "1Step", Rec == "rec") %>% select(-Rec, -ForecastInterval, -Level)
) %>%
  kable(
    booktabs = TRUE, format = "latex", digits = 1, linesep = "",
    caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - Rolling origin 28-step-ahead - Wikipedia dataset",
    col.names = c("Level", rep(c("ETS", "ARIMA", "OLS"), 2))
  ) %>%
  add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
  kable_styling(position = "center", latex_options = "hold_position")
```

```{r wikipediadataresultRMSE, results='asis', dependson="Readwikipedia"}
bind_cols(
  filter(rmse2, ForecastInterval == "28Step", Rec == "unrec") %>% select(-Rec, -ForecastInterval),
  filter(rmse2, ForecastInterval == "28Step", Rec == "rec") %>% select(-Rec, -ForecastInterval, -Level)
) %>%
  kable(
    booktabs = TRUE, format = "latex", digits = 1, linesep = "",
    caption = "Mean(RMSE) for ETS, ARIMA and OLS with and without reconciliation - Fixed origin 28-step-ahead - Wikipedia dataset",
    col.names = c("Level", rep(c("ETS", "ARIMA", "OLS"), 2))
  ) %>%
  add_header_above(c("", "Unreconciled" = 3, "Reconciled" = 3)) %>%
  kable_styling(position = "center")
```

```{r boxplotrollingwiki, fig.align="center", fig.cap="Box plots of forecast errors for reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for rolling origin 28-step-ahead Wikipedia pageviews.", out.width="100%"}
## 1-step-ahead
error.wiki %>%
  filter(ForecastInterval == "1Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  )) %>%
  ggplot(aes(x = id, y = Value, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 3, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

```{r boxplotwiki, fig.align="center", fig.cap="Box plots of forecast errors for reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for fixed origin 28-step-ahead Wikipedia pageviews.", out.width="100%"}
## 28-step-ahead
error.wiki %>%
  filter(ForecastInterval == "28Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  )) %>%
  ggplot(aes(x = id, y = Value, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 3, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

In Figures \@ref(fig:forecstrolling28wikitotal) and \@ref(fig:forecstrolling28wiki), we display results for the total and one of the bottom level series, 'desktopusenPho' (desktop-user-english-photo sharing). The plot shows rolling and fixed origin 28-step-ahead forecast results for ETS, ARIMA and OLS, with (solid lines) and without (dashed lines) applying reconciliation. We see that the OLS forecasting model performs close to the other two methods, and reconciliation improves the forecasts.

```{r forecstrolling28wikitotal, fig.align="center", fig.cap="The actual test set for the 'Total' series compared to the forecasts from reconciled and unreconciled ETS, ARIMA and OLS methods for rolling and fixed origin 28-step-ahead Wikipedia pageviews.", out.width="100%"}
### one of the bottom level series
h1 <- forecast.wiki %>%
  filter(Series == "Total", ForecastInterval == "1Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Rolling origin 28-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      OLSX = "yellow",
      ARIMAX = "orchid1",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(linetype = FALSE)
h2 <- forecast.wiki %>%
  filter(Series == "Total", ForecastInterval == "28Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Fixed origin 28-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      OLSX = "yellow",
      ARIMAX = "orchid1",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(color = FALSE)
gridExtra::grid.arrange(h1, h2, nrow = 2)
```

```{r forecstrolling28wiki, fig.align="center", fig.cap="The actual test set for the 'desktopusenPho21' bottom level series compared to the forecasts from reconciled and unreconciled ETS, ARIMA and OLS methods for rolling and fixed origin 28-step-ahead Wikipedia pageviews.", out.width="100%"}
### one of the bottom level series
f1 <- forecast.wiki %>%
  filter(Series == "desktopusenPho21", ForecastInterval == "1Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle(" Rolling origin 28-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      OLSX = "yellow",
      ARIMAX = "orchid1",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(linetype = FALSE)
f2 <- forecast.wiki %>%
  filter(Series == "desktopusenPho21", ForecastInterval == "28Step") %>%
  rename(Reconciled = Rec) %>%
  ggplot(aes(x = date, y = Count, colour = Model, linetype = Reconciled)) +
  geom_line() +
  xlab("Horizon") + ylab("Count") + ggtitle("Fixed origin 28-step-ahead") +
  scale_color_manual(
    name = "Series",
    values = c(
      ETS = "green",
      ARIMA = "blue",
      OLS = "red",
      OLSX = "yellow",
      ARIMAX = "orchid1",
      Actual = "black"
    )
  ) +
  theme_bw() + guides(color = FALSE)
gridExtra::grid.arrange(f1, f2, nrow = 2)
```

Lastly, Table \@ref(tab:wikipediadatacomputationtime) presents the computation times for all three methods. ETS and ARIMA are clearly much more computationally heavy compared with OLS. As in the Australian tourism dataset, running reconciliation does not have much effect on computation time.

```{r wikipediadatacomputationtime, echo=FALSE, results='asis',message = FALSE}
table2 <- matrix(NA, nrow = 3, ncol = 5)
table2[, 1] <- c("ETS", "ARIMA", "OLS")
table2[, 2] <- c("13963.93", "10327.02", "82.55")
table2[, 3] <- c("13963.96", "10327.15", "82.62")
table2[, 4] <- c("450.89", "670.40", "35.39")
table2[, 5] <- c("450.92", "670.44", "35.43")
kable(table2,
  align = c("c", "c"), format = "latex", booktabs = T, linesep = "", caption = "Computation time (seconds) for ETS, ARIMA and OLS with and without reconciliation - Rolling and fixed origin 28-step-ahead - Wikipedia dataset",
  col.names = c("", "Unreconciled", "Reconciled", "Unreconciled", "Reconciled")
) %>%
  column_spec(1:3, width = "3cm") %>%
  add_header_above(c("", "Rolling origin" = 2, "Fixed origin" = 2)) %>%
  add_header_above(c("", "Computation time (secs)" = 4)) %>%
  kable_styling(position = "center", full_width = F)
```

# Conclusion

We proposed a linear model approach to forecast hierarchical or grouped time series in a much faster way, but with accuracy that nearly matches that of forecast methods such as ETS and ARIMA. This is especially useful in large collections of time series, as is typical in hierarchical and grouped structures. Although ETS and ARIMA are advantageous in terms of forecasting power and accuracy, they can be computationally heavy when facing large collections of time series in the hierarchy. Adding another faster option for calculating base forecasts was our purpose in this research. Here we suggest a linear model, OLS, instead of ETS and ARIMA which is not computationally intensive. We also showed that OLS can compete with ETS and ARIMA in terms of forecasting accuracy. An important feature of our model is its ability to easily include external information such as holiday dummies or other external series. We also note that OLS has the additional practical advantage of handling missing data while ETS and ARIMA require imputation. @pennings2017 proposed another approach for forecasting hierarchical time series using state space models. Although thier approach is flexible in handling outliers, missing data and external features it is less flexible to different kinds of datasets and it is computationally more complex. In contrast to the computation adjustment, since our proposed approach is  computationally cheap it is more practical and especially useful for model selection.

# Acknowledgements {-}

The first and third authors of this research were partially funded by Ministry of Science and Technology (MOST), Taiwan [Grant 106-2420-H-007-019].

\clearpage

# Appendix A  {#appendixA -}

We provide boxplots of the scaled forecasted errors for the tourism example. These plots are displayed for both rolling forward and multiple-step-ahead forecasts.

```{r boxplotrollingtourismappendix, fig.align="center", fig.cap="Box plots of scaled forecast errors from reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for rolling origin 24-step-ahead tourism demand.", out.width="88%"}
## 1-step-ahead
error.tourism.1 <- error.tourism %>%
  filter(ForecastInterval == "1Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  ))

error.tourism.2 <- split(error.tourism.1, error.tourism.1$id)
library(plyr)
error.transform.tourism <- lapply(error.tourism.2, function(x) ddply(x, "Series", transform,
    value.scale = (Value - mean(Value)) / (sd(Value))
  ))

do.call("rbind", error.transform.tourism) %>%
  ggplot(aes(x = id, y = value.scale, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 4, scales = "fixed") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

```{r boxplottourismappendix, fig.align="center", fig.cap="Box plots of scaled forecast errors from reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for fixed origin 24-step-ahead tourism demand.", out.width="88%"}
## 24-step-ahead
error.tourism.24 <- error.tourism %>%
  filter(ForecastInterval == "24Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  ))

error.tourism.22 <- split(error.tourism.24, error.tourism.1$id)
library(plyr)
error.transform.tourism.24 <- lapply(error.tourism.22, function(x) ddply(x, "Series", transform,
    value.scale = (Value - mean(Value)) / (sd(Value))
  ))

do.call("rbind", error.transform.tourism.24) %>%
  ggplot(aes(x = id, y = value.scale, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 4, scales = "fixed") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

\clearpage

<!--# Appendix B  {#appendixB -}

We provide boxplots of the scaled forecasted errors for the Wikipedia pageviews example. These plots are displayed for both rolling forward and multiple-step-ahead forecasts.

```{r boxplotrollingwikiappendix, fig.align="center", fig.cap="Box plots of scaled forecast errors from reconciled and unreconciled ETS, ARIMA and OLS methods at each hierarchical level for rolling origin 28-step-ahead Wikipedia pageviews.", out.width="88%"}
## 1-step-ahead
error.wiki.1 <- error.wiki %>%
  filter(ForecastInterval == "1Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  ))

error.wiki.2 <- split(error.wiki.1, error.wiki.1$id)
library(plyr)
error.transform.wiki <- lapply(error.wiki.2, function(x) ddply(x, "Series", transform,
    value.scale = (Value - mean(Value)) / (sd(Value))
  ))

do.call("rbind", error.transform.wiki) %>%
  ggplot(aes(x = id, y = value.scale, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 3, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

```{r boxplotwikiappendix, fig.align="center", fig.cap="Box plots of scaled forecast errors from reconciled and unreconciled ETS, ARIMA and OLS method at each hierarchical level for fixed origin 28-step-ahead Wikipedia pageviews.", out.width="88%"}
## 28-step-ahead
error.wiki.28 <- error.wiki %>%
  filter(ForecastInterval == "28Step") %>%
  mutate(id = factor(paste(Method, Rec, sep = "."),
    levels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec"),
    labels = c("ETS.rec", "ETS.unrec", "ARIMA.rec", "ARIMA.unrec", "OLS.rec", "OLS.unrec")
  ))

error.wiki.22 <- split(error.wiki.28, error.wiki.1$id)
library(plyr)
error.transform.wiki.28 <- lapply(error.wiki.22, function(x) ddply(x, "Series", transform,
    value.scale = (Value - mean(Value)) / (sd(Value))
  ))

do.call("rbind", error.transform.wiki.28) %>%
  ggplot(aes(x = id, y = value.scale, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 3, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "ETS.rec" = "green",
    "ETS.unrec" = "lightgreen",
    "ARIMA.rec" = "blue",
    "ARIMA.unrec" = "lightblue",
    "OLS.rec" = "pink4",
    "OLS.unrec" = "pink"
  )) +
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```
-->
\clearpage

# Appendix B  {#appendixB -}

In Figure \@ref(fig:loopsvsmatrix), we compare the forecasts obtained using separate regression models versus matrix computation for the Australian domestic tourism example. Although mathematically both approaches should yield the same results, the results in practice are slightly different due to numerical deviations. Table \@ref(tab:Tourismdatacomputationtimeappendix) shows the matrix approach is computationally heavier due to greater memory requirements.

```{r Readloopsvsmatrix, results='hide'}
forecast.tourism.loops.matrix <- readr::read_csv("Paper-Figures/results_Tourism/loopsvsmatrix.csv")
```

```{r loopsvsmatrix, fig.align="center", fig.cap="Comparison of the forecasts obtained  using a matrix approach and separate regression models to reconcile forecasts for rolling and fixed origin 24-step-ahead tourism demand (bottom level series only).", out.width="100%"}
### qqplot - rec
 lvsm.1 <-
  forecast.tourism.loops.matrix %>%
  filter(Level == "level7", ForecastInterval == "1Step") %>%
  ggplot(aes(x = OLS.rec, y = OLS.rec.matrix)) + geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ylim(0,2600) +
  xlab("Separate regression models") + ylab("Matrix approach") + ggtitle("Rolling origin 24-step-ahead") +
  theme_bw() + guides(linetype = FALSE)

 lvsm.24 <-
  forecast.tourism.loops.matrix %>%
   filter(Level == "level7", ForecastInterval == "24Step") %>%
   ggplot(aes(x = OLS.rec, y = OLS.rec.matrix)) + geom_point() +
   geom_smooth(method = "lm", se = FALSE) +
   ylim(0,2600) +
   xlab("Separate regression models") + ylab("Matrix approach") + ggtitle("Fixed origin 24-step-ahead") +
   theme_bw() + guides(linetype = FALSE)

 gridExtra::grid.arrange(lvsm.1,lvsm.24, nrow=1)
```

```{r Tourismdatacomputationtimeappendix, results='asis'}
table2 <- matrix(NA, nrow = 2, ncol = 5)
table2[, 1] <- c("Matrix approach", "Separate models")
table2[, 2] <- c("202.06", "48.40")
table2[, 3] <- c("209.84", "48.31")
table2[, 4] <- c("87.73", "16.66")
table2[, 5] <- c("105.69", "16.85")
kable(table2,
  align = c("l", rep("r", 4)), format = "latex", booktabs = TRUE, linesep = "",
  caption = "Computation time (seconds) for OLS using the matrix approach and separate regression models, with and without reconciliation, on a rolling and fixed origin for 24 steps ahead, using the tourism dataset.",
  col.names = c("", "Unreconciled", "Reconciled", "Unreconciled", "Reconciled")
) %>%
  column_spec(1:3, width = "3cm") %>%
  add_header_above(c("", "Rolling origin" = 2, "Fixed origin" = 2)) %>%
  kable_styling(position = "center", full_width = FALSE)
```

\clearpage

# Appendix C  {#appendixC -}

In Figure  \@ref(fig:boxplotrollingtourismweight) and \@ref(fig:boxplottourismwight) we display a box plot comparison of the results using two different reconciliation functions, weighted and unweighted (Equations \@ref(eq:initialW) and \@ref(eq:mint)), for ETS, ARIMA and the proposed OLS methods. We can see that  for the base level the unweighted approach is similar, but for some lower levels the weighted approach provides more accurate forecasts.

```{r Readtourismweight, results='hide'}
error.tourism.weight <- readr::read_csv("Paper-Figures/results_Tourism/error.tourism.weight.csv")
```

```{r boxplotrollingtourismweight, fig.align="center", fig.cap="Box plots of forecast errors from OLS and WLS reconciled ETS, ARIMA and OLS methods at each hierarchical level for rolling origin 24-step-ahead tourism demand.", out.width="100%"}
## 1-step-ahead
error.tourism.weight %>%
  filter(ForecastInterval == "1Step") %>%
  mutate(id = factor(Method,
    levels = c("weighted.ETS", "ETS", "weighted.ARIMA", "ARIMA", "weighted.OLS", "OLS"),
    labels = c("weighted.ETS", "ETS", "weighted.ARIMA", "ARIMA", "weighted.OLS", "OLS")
  )) %>%
  ggplot(aes(x = id, y = Value, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level,ncol = 4,  scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "weighted.ETS" = "green",
    "ETS" = "lightgreen",
    "weighted.ARIMA" = "blue",
    "ARIMA" = "lightblue",
    "weighted.OLS" = "pink4",
    "OLS" = "pink"
  )) +
  #coord_flip(clip = "off")+
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

```{r boxplottourismwight, fig.align="center", fig.cap= "Box plots of forecast errors from OLS and WLS reconciled ETS, ARIMA and OLS methods at each hierarchical level for fixed origin 24-step-ahead tourism demand.", out.width="100%"}
## 24-step-ahead
error.tourism.weight %>%
  filter(ForecastInterval == "24Step") %>%
  mutate(id = factor(Method,
    levels = c("weighted.ETS", "ETS", "weighted.ARIMA", "ARIMA", "weighted.OLS", "OLS"),
    labels = c("weighted.ETS", "ETS", "weighted.ARIMA", "ARIMA", "weighted.OLS", "OLS")
  )) %>%
  ggplot(aes(x = id, y = Value, fill = id)) +
  geom_boxplot(alpha = 0.5) +
  xlab("Method") + ylab("Error") +
  facet_wrap(~Level, ncol = 4, scales = "free_y") +
  guides(fill = guide_legend(nrow = 1, bycol = TRUE)) +
  theme_minimal() +
  scale_fill_manual(values = c(
    "weighted.ETS" = "green",
    "ETS" = "lightgreen",
    "weighted.ARIMA" = "blue",
    "ARIMA" = "lightblue",
    "weighted.OLS" = "pink4",
    "OLS" = "pink"
  )) +
  #coord_flip(clip = "off")+
  theme_light() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
    axis.text = element_text(size = 10),
    strip.text = element_text(size = 12),
    axis.title = element_text(size = 12, face = "bold"),
    legend.position = "none"
  )
```

\clearpage



